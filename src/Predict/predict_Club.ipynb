{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Data/Club/all_data_of_clubs.csv')\n",
    "data.rename(columns={\"Unnamed: 0\": \"Team\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Team', 'Fixtures', 'Performances']\n",
    "data_cleaned = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['Y_champion'] = (data_cleaned['Rank'] == 1).astype(int)\n",
    "data_cleaned['Y_top4'] = (data_cleaned['Rank'] <= 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'Goals', 'Goals per match', 'Shots', 'Shots on target', 'Shooting accuracy %',\n",
    "    'Passes', 'Passes per match', 'Pass accuracy %', 'Clean sheets', 'Goals Conceded',\n",
    "    'Goals conceded per match', 'Tackles', 'Tackle success %', 'Yellow cards', \n",
    "    'Red cards', 'Points'\n",
    "]\n",
    "\n",
    "X_champion = data_cleaned[selected_features]\n",
    "y_champion = data_cleaned['Y_champion']\n",
    "\n",
    "X_top4 = data_cleaned[selected_features]\n",
    "y_top4 = data_cleaned['Y_top4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_champion, X_test_champion, y_train_champion, y_test_champion = train_test_split(\n",
    "    X_champion, y_champion, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_top4, X_test_top4, y_train_top4, y_test_top4 = train_test_split(\n",
    "    X_top4, y_top4, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_champion_scaled = scaler.fit_transform(X_train_champion)\n",
    "X_test_champion_scaled = scaler.transform(X_test_champion)\n",
    "X_train_top4_scaled = scaler.fit_transform(X_train_top4)\n",
    "X_test_top4_scaled = scaler.transform(X_test_top4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Logistic Regression for Champion Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champion Prediction Accuracy (Logistic Regression): 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_champion = LogisticRegression(random_state=42, max_iter=500)\n",
    "model_champion.fit(X_train_champion_scaled, y_train_champion)\n",
    "y_pred_champion = model_champion.predict(X_test_champion_scaled)\n",
    "accuracy_champion = accuracy_score(y_test_champion, y_pred_champion)\n",
    "print(\"Champion Prediction Accuracy (Logistic Regression):\", accuracy_champion)\n",
    "print(classification_report(y_test_champion, y_pred_champion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Random Forest for Top-4 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-4 Prediction Accuracy (Random Forest): 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.33      0.50      0.40         6\n",
      "weighted avg       0.44      0.67      0.53         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_top4_rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "model_top4_rf.fit(X_train_top4_scaled, y_train_top4)\n",
    "y_pred_top4_rf = model_top4_rf.predict(X_test_top4_scaled)\n",
    "accuracy_top4_rf = accuracy_score(y_test_top4, y_pred_top4_rf)\n",
    "print(\"Top-4 Prediction Accuracy (Random Forest):\", accuracy_top4_rf)\n",
    "print(classification_report(y_test_top4, y_pred_top4_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Probabilities to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_champion_scaled = scaler.fit_transform(X_champion)\n",
    "X_top4_scaled = scaler.fit_transform(X_top4)\n",
    "\n",
    "data_cleaned['Champion_Probability'] = model_champion.predict_proba(X_champion_scaled)[:, 1]\n",
    "data_cleaned['Top4_Probability'] = model_top4_rf.predict_proba(X_top4_scaled)[:, 1]\n",
    "\n",
    "export_data = data_cleaned[['Rank', 'Points', 'Champion_Probability', 'Top4_Probability']]\n",
    "export_data.insert(0, 'Team', data['Team'])\n",
    "\n",
    "export_data.to_csv('../../Data/Club/team_probabilities.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
